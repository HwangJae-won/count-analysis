from transformers import pipeline
import pandas as pd
from logger import logger
from collections import defaultdict
import os

def extract_context_sentences(text, keywords, window_size=5):
    """
    í…ìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œë³„ ë¬¸ë§¥(ë¬¸ì¥)ì„ ì¶”ì¶œ
    - text: ì „ì²´ í…ìŠ¤íŠ¸ (str)
    - keywords: ë¬¸ë§¥ì„ ì¶”ì¶œí•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
    - window_size: í‚¤ì›Œë“œ ì£¼ë³€ ë‹¨ì–´ë¥¼ í¬í•¨í•œ ë¬¸ë§¥ í¬ê¸°
    - return: {ë‹¨ì–´: [ë¬¸ì¥ë“¤]} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    context_sentences = defaultdict(list)

    # í…ìŠ¤íŠ¸ë¥¼ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
    sentences = text.split(".")

    for sentence in sentences:
        for keyword in keywords:
            if keyword in sentence:
                # í‚¤ì›Œë“œê°€ í¬í•¨ëœ ë¬¸ì¥ ì¶”ì¶œ
                context_sentences[keyword].append(sentence.strip())

    return context_sentences

sentiment_analyzer = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

def analyze_sentiment_with_context(frequencies, context_sentences, output_path):
    """
    ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ë¹ˆë„ ìƒìœ„ 100ê°œ ë‹¨ì–´ì˜ ê°ì • ë¶„ì„ ìˆ˜í–‰
    - ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ë§¥ì—ì„œ ê°ì • ë¶„ì„ì„ ìˆ˜í–‰í•˜ì—¬ ê¸/ë¶€ì • ë¹„ìœ¨ì„ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ê°ì • ê²°ì •
    """
    try:
        sentiment_data = []

        for word, freq in frequencies[:100]:  # ìƒìœ„ 100ê°œ ë‹¨ì–´ë§Œ ë¶„ì„
            if word not in context_sentences or not context_sentences[word]:
                continue  # ë¬¸ë§¥ì´ ì—†ëŠ” ë‹¨ì–´ëŠ” ìŠ¤í‚µ
            
            positive_count = 0
            negative_count = 0
            total_count = 0

            for sentence in context_sentences[word]:  # í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ë“¤
                try:
                    # ë¬¸ë§¥ ê¸°ë°˜ ê°ì • ë¶„ì„ ìˆ˜í–‰
                    result = sentiment_analyzer(sentence)
                    sentiment = result[0]['label'].lower()  # ì˜ˆ: "POSITIVE", "NEGATIVE", "NEUTRAL"

                    if "positive" in sentiment:
                        positive_count += 1
                    elif "negative" in sentiment:
                        negative_count += 1

                    total_count += 1

                except Exception as e:
                    logger.warning(f"ë¬¸ì¥ ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

            # ë‹¨ì–´ë³„ ìµœì¢… ê°ì • ê²°ì • (ì¤‘ë¦½ ì œì™¸)
            if total_count == 0:
                continue  # ë¬¸ë§¥ ë¶„ì„ì´ ì•ˆ ëœ ë‹¨ì–´ëŠ” ì œì™¸
            
            if positive_count > negative_count:
                final_sentiment = "ê¸ì •"
            elif negative_count > positive_count:
                final_sentiment = "ë¶€ì •"
            else:
                final_sentiment = "ì¤‘ë¦½" # ê°ì • ë¶„ë¥˜ê°€ ì• ë§¤í•œ ê²½ìš° ì œì™¸

            sentiment_data.append({"ë‹¨ì–´": word, "ë¹ˆë„": freq, "ê°ì •": final_sentiment})

        # ğŸ“Œ ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ë¡œê·¸ ì¶œë ¥ í›„ ì¢…ë£Œ
        if not sentiment_data:
            logger.error("âš  ê°ì • ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤! ë¹ˆ ë°ì´í„°ì…‹ì„ í™•ì¸í•˜ì„¸ìš”.")
            return


        # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì €ì¥
        df = pd.DataFrame(sentiment_data)
        df.to_csv(output_path, index=False, encoding="utf-8-sig")
        logger.info(f"âœ… ê°ì • ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {output_path}")

    except Exception as e:
        logger.error(f"[Sentiment][analyze_sentiment_with_context]: {e}")